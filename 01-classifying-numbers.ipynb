{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Symbols\n",
    "\n",
    "\n",
    "- Torch is main pytorch module. \n",
    "- The `nn` module contains things like layer definitions, activations, loss functions etc.\n",
    "- The helper module `functional` provides almost same functionality as the `nn` module. Don't need to initialize object for activation function.\n",
    "- The `optim` module contains the hyper-optimizers\n",
    "- `torchvision` is the computer vision module of pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F    \n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "\n",
    "- In Pytorch, to define the neural network model, you have to define class e.g. `Net`. It has to inherit from the `nn` module.\n",
    "- Another way is sequential way => define what layers your NN has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \"\"\"\n",
    "        - We have 3 layers (500, 1000, 10). The last one is importance since we have 10 classes and we need 10 output neurons.\n",
    "        - The args contain  no. of input and output nodes. E.g. input node of first layer has 784 nodes. \n",
    "        - Why 784? Coz the MNIST dataset has 28x28 px images = 784\n",
    "        - Last layer is more specific, because we have 10 classes that we're trying to recognise.\n",
    "        - fc = fully connected\n",
    "        \"\"\"\n",
    "        self.fc1 = nn.Linear(784, 500)\n",
    "        self.fc2 = nn.Linear(500, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 10)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    - In Pytorch, if you define forward pass through network, then it uses `autograd` library to automatically calculate the backward pass.\n",
    "    - it takes `x` vector or tensor as input.\n",
    "    - the vector is of size 784 at the beginning.\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)   # x.view(<batch-size>, 784). When batch-size = -1 => you don't care about the batch size.\n",
    "        \n",
    "        x = F.relu(self.fc1(x))  # fc layer 1 is connected to input vector. And ReLU activation function is applied to it.\n",
    "        x = F.relu(self.fc2(x))  # do the same but for layer two.\n",
    "        x = self.fc3(x)          # don't apply AF here. Only Linear function\n",
    "\n",
    "        \"\"\"\n",
    "        - logarithmic softmax function applied here. Output of network isn't of size 10 where every value = probability\n",
    "        - softmax value which has highest probability.\n",
    "        \"\"\"\n",
    "        return F.log_softmax(x, dim=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "We use `DataLoader` and `DataSet` `torch` `util` classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', \n",
    "                   train=True, # train parameter here decides whether the dataset is training or testing as per the boolean flag\n",
    "                   download=True, \n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(), transforms.Normalize((0.1307,),(0.3081,))\n",
    "                    ])),\n",
    "                    batch_size=128, shuffle=True  # shuffle set as True to make results generic\n",
    "                )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', \n",
    "                   train=False, \n",
    "                   download=True, \n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(), transforms.Normalize((0.1307,),(0.3081,))\n",
    "                    ])),\n",
    "                    batch_size=128, shuffle=True\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing loops\n",
    "\n",
    "- Boiler plate code for training and testing.\n",
    "- Most ML Frameworks don't expose this part of code.\n",
    "- However since PyTorch framework is used for experimental research, you have full control over how a model is trained/tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "the train() accepts the \n",
    "    neural network `model`, \n",
    "    the `device` on which to run it, \n",
    "    the `train_loader` training dataset, epoch and optimizer\n",
    "\"\"\"\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()   # biases in the model can be changed.\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):  # running with enum, coz wanna know batch index current loss\n",
    "        data, target = data.to(device), target.to(device)   # move data and target to the device e.g. graphics card. edge programming\n",
    "        optimizer.zero_grad()  # set up fresh calculations\n",
    "        output = model(data)   # running data through fwd pass and get output at current step\n",
    "        loss = F.nll_loss(output, target)  # loss at curr. step using negative log likelihood loss coz it works well for softmax output\n",
    "        loss.backward()    # PyTorch feature. By doing back-propagation through network, can be done automatically.\n",
    "        optimizer.step()   # changes the parameters in the network\n",
    "        if batch_idx%100 == 0:\n",
    "            # print every 100 batches\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx*len(data), len(train_loader.dataset), 100.*batch_idx/len(train_loader), loss.item()\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    model.eval()   # model during eval mode will NOT change parameters\n",
    "    test_loss = 0\n",
    "    correct = 0    # we count how many test sets got correct\n",
    "    with torch.no_grad():  # speeds up the process. We tell don't remeber gradients so make faster processing\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)   # running the data through the model\n",
    "\n",
    "            # since we're testing in batch, we're interested in only sum of all losses in the batch\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  \n",
    "            pred = output.argmax(dim=1, keepdim=True)   # get index of maxiumum o/p probability from the o/p vector\n",
    "\n",
    "            # count how many samples we got correct/incorrect. Compare the correct labels in batch and sum them up.\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest Set: Average Loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), 100.*correct/len(test_loader.dataset)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.299149\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.434354\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.288404\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.237406\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.229125\n",
      "\n",
      "Test Set: Average Loss: 0.1687, Accuracy: 9504/10000 (95%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.117743\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.153799\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.088753\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.048535\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.125453\n",
      "\n",
      "Test Set: Average Loss: 0.1097, Accuracy: 9647/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.168136\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.094888\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.057408\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.085881\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.055911\n",
      "\n",
      "Test Set: Average Loss: 0.0859, Accuracy: 9733/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "torch.manual_seed(42) # for reproducible results, set random weight\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"mps\") # PyTorch added support for M1 GPU on May 2022\n",
    "\n",
    "model = Net().to(device)  # Move the model to the device.\n",
    "\"\"\"\n",
    "- We've to tell it what it is optimizing. \n",
    "- A helper method parameters() can be called in any neural network model in PyTorch\n",
    "- It calls all the params based on the fwd function.\n",
    "\"\"\"\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.5) \n",
    "\n",
    "# test before training\n",
    "\n",
    "for epoch in range(1, 3+1):  # train for 3 epochs, and test after running each epoch.\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "\n",
    "torch.save(model.state_dict(), \"mnist.pt\")  # save the model to `mnist.pt`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x3142a2610>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_image = test_loader.dataset.data[1200]\n",
    "plt.imshow(test_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-173.2375,  -63.7640, -233.0796,  -67.2465, -341.3364, -221.4524,\n",
       "         -284.8539, -358.5439,    0.0000, -290.2952]], device='mps:0',\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN THE IMAGE THROUGH MODEL\n",
    "#out = model(test_image.float().cuda()))  <--- for CUDA support\n",
    "out = model(test_image.float().to(torch.device('mps')))  # <--- for Mac M1 GPUs\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in above output, all values in the 10 unit vector output are negative or zero except for the index value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8], device='mps:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.argmax(dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
